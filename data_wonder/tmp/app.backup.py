# ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
# ì˜¤ëŠ˜ ì£¼ë¬¸ì‹¤ì ì„ ì•Œë ¤ì¤˜. ìµœê·¼ ì£¼ë¬¸ì‹œê°„ ë¶€í„° í™•ì¸í• ê»˜
# ê°€ì¥ ì ê²Œ íŒ”ë¦° ìƒí’ˆì„ ì•Œë ¤ì¤˜
# ì˜¤ëŠ˜ ìƒí’ˆë³„ íŒë§¤ì•¡ rank 5 ë¥¼ ì•Œë ¤ì¤˜


import streamlit as st
import fitz  
import logging
import boto3
import json
import os
import re
import pymysql
import pandas as pd
from dotenv import load_dotenv
from datetime import datetime
from langchain_community.chat_models import BedrockChat
from langchain_community.embeddings import BedrockEmbeddings
from langchain_community.vectorstores import OpenSearchVectorSearch
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.llms.bedrock import Bedrock
from opensearchpy import OpenSearch, RequestsHttpConnection
from opensearchpy.helpers import bulk

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

INIT_MESSAGE = {"role": "assistant", 
                "type": "text",
                "content": """ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” <i><b>ë² ë“œë½ì˜ Claude3</b></i> ì…ë‹ˆë‹¤. 
                                                   <br>í˜„ì¬ <font color='#32CD32;'><b>ì†í¥ë¯¼</b></font>ê³¼ <font color='#32CD32;'><b>AWS EC2</b></font>ì— ëŒ€í•´ í•™ìŠµë˜ì–´ ìˆê³  
                                                   ì™¼ìª½ ì„¹ì…˜ì—ì„œ <font color='red'><b>PDF ì—…ë¡œë“œ</b></font>ë¥¼ í†µí•´ ì¶”ê°€ í•™ìŠµì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <br>ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"""}

# ì°¸ê³ . íŠ¹íˆ order_dt ëŠ” ë¬¸ìì—´ì´ë¯€ë¡œ ë¹„êµë˜ëŠ” ê°’ë„ ë¬¸ìì—´ì´ì–´ì•¼ í•œë‹¤.
# ì°¸ê³ . SQLì€ sql code íƒœê·¸ë¥¼ ì‚¬ìš©í•´ì„œ í‘œì‹œí•´ì£¼ê³ , í•˜ë‚˜ì˜ SQLë§Œ ì‘ì„±í•´ì¤˜
# ì°¸ê³ . where ì»¬ëŸ¼A = ìƒìˆ˜B ì¼ ë–„ ì»¬ëŸ¼Aì™€ ìƒìˆ˜Bì˜ ë°ì´í„°íƒ€ì…ì´ ë‹¤ë¥´ë‹¤ë©´ ìƒìˆ˜Bë¥¼ í˜•ë³€í™˜í•´ì„œ ë°ì´í„°íƒ€ì…ì„ ë™ì¼í•˜ê²Œ ë§ì¶°ì¤˜.ì˜ˆë¥¼ ë“¤ì–´ order_dt = CURDATE() ì¼ ê²½ìš° order_dt = date_format(curdate(), '%y-%m-%d') ë¡œ ì‚¬ìš©í•´ì¤˜
PROMPT_HELP = """

ì°¸ê³ . ë°ì´í„° ì§ˆì˜ê°€ í•„ìš”í•œ ê²ƒë§Œ SQLì„ ë§Œë“¤ì–´ì¤˜
ì°¸ê³ . ì§ˆë¬¸ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” SQLì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤ë©´ SQLë¥¼ ì‘ì„±í•´ì¤˜.
ì°¸ê³ . SQLì€ markdownì˜ ì½”ë“œ sql íƒœê·¸ ì•ˆì— ë„£ì–´ì¤˜.
ì°¸ê³ . markdown ì½”ë“œ sql íƒœê·¸ ì•ˆì—ëŠ” í•˜ë‚˜ì˜ sql ë§Œ ë„£ì–´ì¤˜.
ì°¸ê³ . SELECT ì ˆì˜ ì»¬ëŸ¼ alias ëŠ” ëŒ€ë„ë¡ í•œê¸€ë¡œ ë§Œë“¤ì–´ì¤˜.
ì°¸ê³ . where ì ˆì—ì„œ ì»¬ëŸ¼ì„ í˜•ë³€í™˜ì„ ìœ„í•´ ê°€ê³µí•˜ì§€ ë§ì•„ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ order_dt ë¥¼ DATE(order_dt)ë¡œ ë³€í™˜í•˜ì§€ ë§ì•„ë¼.
ì°¸ê³ . where ì»¬ëŸ¼A = ìƒìˆ˜B ì¼ ë–„ ì»¬ëŸ¼Aì™€ ìƒìˆ˜Bì˜ ë°ì´í„°íƒ€ì…ì´ ë‹¤ë¥´ë‹¤ë©´ ìƒìˆ˜Bë¥¼ í˜•ë³€í™˜í•´ì„œ ë°ì´í„°íƒ€ì…ì„ ë™ì¼í•˜ê²Œ ë§ì¶°ì¤˜.ì˜ˆë¥¼ ë“¤ì–´ order_dt = CURDATE() ì¼ ê²½ìš° order_dt = date_format(curdate(), '%Y-%m-%d') ë¡œ ì‚¬ìš©í•´ì¤˜
ì°¸ê³ . where ì—ì„œ ë™ì¼í•œ ë°ì´í„°íƒ€ì…ìœ¼ë¡œ ë¹„êµë¥¼ í•  ìˆ˜ ìˆê²Œ ì ì ˆí•œ í˜•ë³€í™˜ì„ í•´ì¤˜.
ì°¸ê³ . SQL ìƒì„± ì‹œ ìµœëŒ€ 10ê°œì˜ ë ˆì½”ë“œë§Œ í‘œì‹œë˜ë„ë¡ Limit 10ì„ SQLì— í¬í•¨ì‹œì¼œì¤˜. ê·¸ë¦¬ê³  Limit 10ì„ ì„ì˜ë¡œ ì¶”ê°€í–ˆë‹¤ê³  ì´ˆë¡ìƒ‰ ê¸€ìë¡œ ì•ˆë‚´í•´ì¤˜.
ì°¸ê³ . SQL ìƒì„± ì‹œ ë³„ë„ì˜ ì •ë ¬ì´ í•„ìš”ì—†ë‹¤ë©´ last_update_time desc ì„ ì •ë ¬ ì¡°ê±´ìœ¼ë¡œ ì¶”ê°€í•´ì¤˜.


"""
################################################################################

load_dotenv()
opensearch_username = os.getenv('OPENSEARCH_USERNAME')
opensearch_password = os.getenv('OPENSEARCH_PASSWORD')
opensearch_endpoint = os.getenv('OPENSEARCH_ENDPOINT')
index_name = 'index_chatbot_test_04'
bedrock_region = 'us-west-2'
stop_record_count = 100
record_stop_yn = False
bedrock_model_id = "anthropic.claude-3-sonnet-20240229-v1:0"
bedrock_embedding_model_id = "amazon.titan-embed-text-v1"

mysql_host = os.getenv('MYSQL_HOST')
mysql_port = os.getenv('MYSQL_PORT')
mysql_user = os.getenv('MYSQL_USER')
mysql_password = os.getenv('MYSQL_PASSWORD')
mysql_db = os.getenv('MYSQL_DB')
################################################################################
    
def get_opensearch_cluster_client():
    opensearch_client = OpenSearch(
        hosts=[{
            'host': opensearch_endpoint,
            'port': 443
            }],
        http_auth=(opensearch_username, opensearch_password),
        index_name = index_name,
        use_ssl=True,
        verify_certs=True,
        connection_class=RequestsHttpConnection,
        timeout=30
        )
    return opensearch_client

def get_bedrock_client():
    bedrock_client = boto3.client("bedrock-runtime", region_name=bedrock_region)
    return bedrock_client    

def create_langchain_vector_embedding_using_bedrock(bedrock_client):
    bedrock_embeddings_client = BedrockEmbeddings(
        client=bedrock_client,
        model_id=bedrock_embedding_model_id)
    return bedrock_embeddings_client    

def create_opensearch_vector_search_client(bedrock_embeddings_client, _is_aoss=False):
    docsearch = OpenSearchVectorSearch(
        index_name=index_name,
        embedding_function=bedrock_embeddings_client,
        opensearch_url=f"https://{opensearch_endpoint}",
        http_auth=(opensearch_username, opensearch_password),
        is_aoss=_is_aoss
    )
    return docsearch

def create_bedrock_llm():
    # claude-2 ì´í•˜
    # bedrock_llm = Bedrock(
    #     model_id=model_version_id, 
    #     client=bedrock_client,
    #     model_kwargs={'temperature': 0}
    #     )
    # bedrock_llm = BedrockChat(model_id=model_version_id, model_kwargs={'temperature': 0}, streaming=True)

    bedrock_llm = BedrockChat(model_id=bedrock_model_id, model_kwargs={'temperature': 0})
    return bedrock_llm

def get_bedrock_client():
    bedrock_client = boto3.client("bedrock-runtime", region_name=bedrock_region)
    return bedrock_client

def create_vector_embedding_with_bedrock(text, bedrock_client):
    payload = {"inputText": f"{text}"}
    body = json.dumps(payload)
    modelId = "amazon.titan-embed-text-v1"
    accept = "application/json"
    contentType = "application/json"

    response = bedrock_client.invoke_model(
        body=body, modelId=modelId, accept=accept, contentType=contentType
    )
    response_body = json.loads(response.get("body").read())

    embedding = response_body.get("embedding")
    return {"_index": index_name, "text": text, "vector_field": embedding}

def extract_sentences_from_pdf(opensearch_client, pdf_file, progress_bar, progress_text):    
    try :
        logging.info(f"Checking if index {index_name} exists in OpenSearch cluster")
        
        exists = opensearch_client.indices.exists(index=index_name)               

        if not exists:
            body = {
                'settings': {
                    'index': {
                        'number_of_shards': 3,
                        'number_of_replicas': 2,
                        "knn": True,
                        "knn.space_type": "cosinesimil"
                    }
                }
            }
            success = opensearch_client.indices.create(index_name, body=body)
            if success:
                body = {
                    "properties": {
                        "vector_field": {
                            "type": "knn_vector",
                            "dimension": 1536
                        },
                        "text": {
                            "type": "keyword"
                        }
                    }
                }
                success = opensearch_client.indices.put_mapping(
                    index=index_name,
                    body=body
                )

        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")    
        all_records = []
        for page in doc:
            all_records.append(page.get_text())

        # URL Scraping
        # doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        # all_text = ""
        # for page in doc:
        #     all_text += page.get_text()
        # doc.close()
        # all_records = re.split(r'(?<=[.!?])\s+', all_text)

        logging.info(f"PDF LIST ê°œìˆ˜ : {len(all_records)}")

        total_records = len(all_records)
        processed_records = 0
        
        bedrock_client = get_bedrock_client()

        all_json_records = []

        for record in all_records:
            if record_stop_yn and processed_records > stop_record_count:
                
                success, failed = bulk(opensearch_client, all_json_records)
                break
            
            records_with_embedding = create_vector_embedding_with_bedrock(record, bedrock_client)
            all_json_records.append(records_with_embedding)
            
            processed_records += 1
            progress = int((processed_records / total_records) * 100)
            progress_bar.progress(progress)
            
            if processed_records % 500 == 0 or processed_records == len(all_records):
                
                success, failed = bulk(opensearch_client, all_json_records)
                all_json_records = []  
        
        progress_text.text("ì™„ë£Œ")
        logging.info("ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ë ˆì½”ë“œ ìƒì„± ì™„ë£Œ")
        
        return total_records
    except Exception as e:
        print(str(e))
        st.error('PDFë¥¼ ì„ë² ë”© í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒë˜ì—ˆìŠµë‹ˆë‹¤.')
        return 0

def find_answer_in_sentences(question):
    try :        
        question = question + PROMPT_HELP
        bedrock_client = get_bedrock_client()
        bedrock_llm = create_bedrock_llm()
        
        bedrock_embeddings_client = create_langchain_vector_embedding_using_bedrock(bedrock_client)
        
        opensearch_vector_search_client = create_opensearch_vector_search_client(bedrock_embeddings_client)
        
        prompt_template = """Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. don't include harmful content

        {context}

        Question: {question}
        Answer:"""
        PROMPT = PromptTemplate(
            template=prompt_template, input_variables=["context", "question"]
        )
        logging.info(f"Starting the chain with KNN similarity using OpenSearch, Bedrock FM {bedrock_model_id}, and Bedrock embeddings with {bedrock_embedding_model_id}")
        
        qa = RetrievalQA.from_chain_type(llm=bedrock_llm, 
                                        chain_type="stuff", 
                                        retriever=opensearch_vector_search_client.as_retriever(),
                                        return_source_documents=True,
                                        chain_type_kwargs={"prompt": PROMPT, "verbose": True},
                                        verbose=True)
        
        
        response = qa(question, return_only_outputs=False)
        
        source_documents = response.get('source_documents')
        # logging.info(f"The answer from Bedrock {bedrock_model_id} is: {response.get('result')}")
        return f"{response.get('result')}"
    except Exception as e:
        if 'index_not_found_exception' in str(e):
            st.error('ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PDF íŒŒì¼ì„ ì—…ë¡œë“œ í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”')
        else:
            print(str(e))
            st.error('ë‹µë³€ì„ ì°¾ëŠ” ê³¼ì •ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
        return "ì˜¤ë¥˜ë¡œ ì¸í•´ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


# def execute_query(sql):
#     try:
#         # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
#         connection = pymysql.connect(host=mysql_host,
#                                      port=int(mysql_port),
#                                      user=mysql_user,
#                                      password=mysql_password,
#                                      database=mysql_db,
#                                      cursorclass=pymysql.cursors.DictCursor)

#         with connection:
#             with connection.cursor() as cursor:
#                 # SQL ì¿¼ë¦¬ ì‹¤í–‰
#                 cursor.execute(sql)
#                 result = cursor.fetchall()  # ëª¨ë“  ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´

#                 # ê²°ê³¼ë¥¼ Streamlitì— í‘œì‹œ
#                 if result:
#                     st.write(result)
#                 else:
#                     st.write("ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

#     except Exception as e:
#         st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def connect_to_database():
    return pymysql.connect(
        host=mysql_host,
        port=int(mysql_port),
        user=mysql_user,
        password=mysql_password,
        database=mysql_db,
        charset='utf8mb4'
    )

# SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜


def execute_query_and_return_df(sql):
    conn = connect_to_database()
    try:
        with conn.cursor() as cursor:
            cursor.execute(sql)
            result = cursor.fetchall()
            df = pd.DataFrame(result, columns=[i[0]
                              for i in cursor.description])
    finally:
        conn.close()
    return df

def main():    
    
    # ê¸°ì¡´ ì—…ë¡œë“œ ë¬¸ì„œ ì‚­ì œ
    # if st.sidebar.button("ê¸°ì¡´ ì—…ë¡œë“œ ë¬¸ì„œ ì‚­ì œ"):
    #     response = opensearch_client.delete_opensearch_index(opensearch_client, index_name)
    #     # st.session_state['question'] = ""  # ì§ˆë¬¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    #     if response:
    #         logging.info("OpenSearch index successfully deleted")
    #         st.sidebar.success("OpenSearch ì¸ë±ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")  # ì„±ê³µ ì•Œë¦¼ ì¶”ê°€
    
    opensearch_client = get_opensearch_cluster_client()
    st.set_page_config(page_title='ğŸ¤– Chat with Bedrock', layout='wide')
    st.header('_Chatbot_ using :blue[OpenSearch] :sunglasses:', divider='rainbow')
    

    if 'qa_history' not in st.session_state:
        st.session_state.qa_history = []

    with st.sidebar:
        st.sidebar.markdown(':smile: **Createby:** chiholee@amazon.com', unsafe_allow_html=True)
        st.sidebar.markdown('---')
        st.title("RAG Embedding")
        pdf_file = st.file_uploader("ChatBotì´ í•™ìŠµí•  PDF ì—…ë¡œë“œ", type=["pdf"], key=None)
        
        if 'last_uploaded' not in st.session_state:
            st.session_state.last_uploaded = None

        if pdf_file is not None and pdf_file != st.session_state.last_uploaded:
            progress_text = st.empty() 
            st.session_state['progress_bar'] = st.progress(0)
            progress_text.text("RAG(OpenSearch) ì„ë² ë”© ì¤‘...")
            record_cnt = extract_sentences_from_pdf(opensearch_client, pdf_file, st.session_state['progress_bar'], progress_text)
            if record_cnt > 0 :
                st.session_state['processed'] = True  
                st.session_state['record_cnt'] = record_cnt  
                st.session_state['progress_bar'].progress(100)  
                st.session_state.last_uploaded = pdf_file
                st.success(f"{record_cnt} Vector ì„ë² ë”© ì™„ë£Œ!")
        
    

    if "messages" not in st.session_state.keys():
        st.session_state.messages = [INIT_MESSAGE]

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["type"] == "text" :
                st.markdown(message["content"], unsafe_allow_html=True)
            elif message["type"] == "data" :
                st.markdown(message["content"][0], unsafe_allow_html=True)
                st.write(':bulb: **ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼**', message["content"][1])

    question = st.chat_input("Say something")

    if question :
        st.session_state.messages.append({"role": "user", 
                                          "type": "text",
                                          "content": question})
        with st.chat_message("user"):
            st.markdown(question, unsafe_allow_html=True)
            
    
    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                answer = find_answer_in_sentences(question)

                sql_queries = re.findall(r'```sql(.*?)```', answer, re.DOTALL)
                st.markdown(answer, unsafe_allow_html=True)

                
                

                if len(sql_queries) > 0 :
                    # st.markdown(sql_queries[0], unsafe_allow_html=True)
                    sql = sql_queries[0]
                    df = execute_query_and_return_df(sql)
                    st.write(':bulb: **ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼**', df)

                    message = {"role": "assistant", 
                               "type": "data",
                               "content": [answer,df]}
                    
                
                else :
                    message = {"role": "assistant",
                               "type": "text",
                               "content": answer}
                    
                
                st.session_state.messages.append(message)






        



if __name__ == "__main__":
    main()
